{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: sklearn in /opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages (0.0)\r\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in /opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages (from sklearn) (0.23.1)\r\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.18.5)\r\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.5.0)\r\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages (from scikit-learn->sklearn) (0.15.1)\r\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages (from scikit-learn->sklearn) (2.1.0)\r\n"
     ]
    }
   ],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "!pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in /opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages (0.15.1)\r\n"
     ]
    }
   ],
   "source": [
    "# install joblib for saving\n",
    "# Restart kernel after installing \n",
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/ml_compile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year_month', 'land_avg_temp', 'land_max_temp', 'land_min_temp',\n",
       "       'land_ocean_avg_temp', 'north_min_temp_anomoly',\n",
       "       'north_max_temp_anomoly', 'north_mean_temp_anomoly', 'global_avg_co2',\n",
       "       'seaice_extent', 'bear_rsf_mean', 'bear_rsf_var', 'num_bears',\n",
       "       'avg_distance_traveled', 'avg_num_land_dens', 'avg_num_ice_dens',\n",
       "       'avg_num_active_dens'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning: Climate x Resource Selection Factor (RSF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df [['year_month', 'land_avg_temp', 'land_max_temp', 'land_min_temp',\n",
    "       'land_ocean_avg_temp', 'north_min_temp_anomoly',\n",
    "       'north_max_temp_anomoly', 'north_mean_temp_anomoly', 'global_avg_co2',\n",
    "       'seaice_extent','avg_distance_traveled' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Drop null values\n",
    "df = df.dropna(axis=0, thresh = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>land_avg_temp</th>\n",
       "      <th>land_max_temp</th>\n",
       "      <th>land_min_temp</th>\n",
       "      <th>land_ocean_avg_temp</th>\n",
       "      <th>north_min_temp_anomoly</th>\n",
       "      <th>north_max_temp_anomoly</th>\n",
       "      <th>north_mean_temp_anomoly</th>\n",
       "      <th>global_avg_co2</th>\n",
       "      <th>seaice_extent</th>\n",
       "      <th>avg_distance_traveled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>447.000000</td>\n",
       "      <td>447.000000</td>\n",
       "      <td>447.000000</td>\n",
       "      <td>447.000000</td>\n",
       "      <td>447.000000</td>\n",
       "      <td>447.000000</td>\n",
       "      <td>447.000000</td>\n",
       "      <td>447.000000</td>\n",
       "      <td>447.000000</td>\n",
       "      <td>8.100000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.226651</td>\n",
       "      <td>14.930488</td>\n",
       "      <td>3.615477</td>\n",
       "      <td>15.641613</td>\n",
       "      <td>0.775022</td>\n",
       "      <td>0.659465</td>\n",
       "      <td>0.686273</td>\n",
       "      <td>366.108054</td>\n",
       "      <td>11.559153</td>\n",
       "      <td>6.017928e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.134906</td>\n",
       "      <td>4.249913</td>\n",
       "      <td>4.010169</td>\n",
       "      <td>1.229699</td>\n",
       "      <td>0.528649</td>\n",
       "      <td>0.567605</td>\n",
       "      <td>0.540999</td>\n",
       "      <td>18.908570</td>\n",
       "      <td>3.185538</td>\n",
       "      <td>6.840158e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.558000</td>\n",
       "      <td>8.071000</td>\n",
       "      <td>-2.853000</td>\n",
       "      <td>13.566000</td>\n",
       "      <td>-0.787000</td>\n",
       "      <td>-1.256000</td>\n",
       "      <td>-1.065000</td>\n",
       "      <td>332.410000</td>\n",
       "      <td>3.565600</td>\n",
       "      <td>1.784230e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.189000</td>\n",
       "      <td>10.696000</td>\n",
       "      <td>-0.308000</td>\n",
       "      <td>14.441000</td>\n",
       "      <td>0.413500</td>\n",
       "      <td>0.253000</td>\n",
       "      <td>0.289000</td>\n",
       "      <td>350.320000</td>\n",
       "      <td>8.842585</td>\n",
       "      <td>1.324565e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.394000</td>\n",
       "      <td>15.174000</td>\n",
       "      <td>3.759000</td>\n",
       "      <td>15.683000</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>0.653000</td>\n",
       "      <td>0.671000</td>\n",
       "      <td>364.310000</td>\n",
       "      <td>12.199871</td>\n",
       "      <td>2.650700e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.185500</td>\n",
       "      <td>19.062000</td>\n",
       "      <td>7.447000</td>\n",
       "      <td>16.801500</td>\n",
       "      <td>1.101500</td>\n",
       "      <td>1.037000</td>\n",
       "      <td>1.029500</td>\n",
       "      <td>382.250000</td>\n",
       "      <td>14.409063</td>\n",
       "      <td>9.822863e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.482000</td>\n",
       "      <td>21.320000</td>\n",
       "      <td>9.715000</td>\n",
       "      <td>17.611000</td>\n",
       "      <td>2.554000</td>\n",
       "      <td>2.465000</td>\n",
       "      <td>2.510000</td>\n",
       "      <td>403.960000</td>\n",
       "      <td>16.341938</td>\n",
       "      <td>2.617030e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       land_avg_temp  land_max_temp  land_min_temp  land_ocean_avg_temp  \\\n",
       "count     447.000000     447.000000     447.000000           447.000000   \n",
       "mean        9.226651      14.930488       3.615477            15.641613   \n",
       "std         4.134906       4.249913       4.010169             1.229699   \n",
       "min         2.558000       8.071000      -2.853000            13.566000   \n",
       "25%         5.189000      10.696000      -0.308000            14.441000   \n",
       "50%         9.394000      15.174000       3.759000            15.683000   \n",
       "75%        13.185500      19.062000       7.447000            16.801500   \n",
       "max        15.482000      21.320000       9.715000            17.611000   \n",
       "\n",
       "       north_min_temp_anomoly  north_max_temp_anomoly  \\\n",
       "count              447.000000              447.000000   \n",
       "mean                 0.775022                0.659465   \n",
       "std                  0.528649                0.567605   \n",
       "min                 -0.787000               -1.256000   \n",
       "25%                  0.413500                0.253000   \n",
       "50%                  0.766000                0.653000   \n",
       "75%                  1.101500                1.037000   \n",
       "max                  2.554000                2.465000   \n",
       "\n",
       "       north_mean_temp_anomoly  global_avg_co2  seaice_extent  \\\n",
       "count               447.000000      447.000000     447.000000   \n",
       "mean                  0.686273      366.108054      11.559153   \n",
       "std                   0.540999       18.908570       3.185538   \n",
       "min                  -1.065000      332.410000       3.565600   \n",
       "25%                   0.289000      350.320000       8.842585   \n",
       "50%                   0.671000      364.310000      12.199871   \n",
       "75%                   1.029500      382.250000      14.409063   \n",
       "max                   2.510000      403.960000      16.341938   \n",
       "\n",
       "       avg_distance_traveled  \n",
       "count           8.100000e+01  \n",
       "mean            6.017928e+08  \n",
       "std             6.840158e+08  \n",
       "min             1.784230e+05  \n",
       "25%             1.324565e+08  \n",
       "50%             2.650700e+08  \n",
       "75%             9.822863e+08  \n",
       "max             2.617030e+09  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Data\n",
    "\n",
    "### Assign X(features) and y(target) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_rsf_null[['land_avg_temp', 'land_max_temp', 'land_min_temp',\n",
    "       'land_ocean_avg_temp', 'north_min_temp_anomoly',\n",
    "       'north_max_temp_anomoly', 'north_mean_temp_anomoly', 'global_avg_co2',\n",
    "       'seaice_extent']]\n",
    "y_rsf = df_rsf_null[\"bear_rsf_mean\"].values.reshape(-1, 1)\n",
    "y_var = df_rsf_null[\"bear_rsf_var\"].values.reshape(-1, 1)\n",
    "print(X.shape, y_rsf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into testing and training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_rsf_train, y_rsf_test = train_test_split(X, y_rsf, test_size=0.2, random_state=42)\n",
    "# X_train, X_test, y_var_train, y_var_test = train_test_split(X, y_var, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMaxScalar to fit and transform X features and y target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit Transform using MinMaxScalar for X features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_minmax = MinMaxScaler().fit(X_train)\n",
    "y_rsf_minmax = MinMaxScaler().fit(y_rsf_train)\n",
    "y_var_minmax = MinMaxScaler().fit(y_var_train)\n",
    "\n",
    "X_train_minmax = X_minmax.transform(X_train)\n",
    "X_test_minmax = X_minmax.transform(X_test)\n",
    "\n",
    "#Target value #1\n",
    "y_rsf_train_minmax = y_rsf_minmax.transform(y_rsf_train)\n",
    "y_rsf_test_minmax = y_rsf_minmax.transform(y_rsf_test)\n",
    "\n",
    "#Target value #2\n",
    "y_var_train_minmax = y_var_minmax.transform(y_var_train)\n",
    "y_var_test_minmax = y_var_minmax.transform(y_var_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression Analysis\n",
    "### Resource Selection Factor Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat model and fit to scaled training data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_minmax, y_rsf_train_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Prediction using a FIT model and plot ==SEE BELOW FOR ALTERNATIVES==\n",
    "predictions = model.predict(X_test_minmax)\n",
    "model.fit(X_train_minmax, y_rsf_train_minmax)\n",
    "\n",
    "plt.scatter(model.predict(X_train_minmax), model.predict(X_train_minmax) - y_rsf_train_minmax, c=\"blue\", label=\"Training Data\")\n",
    "plt.scatter(model.predict(X_test_minmax), model.predict(X_test_minmax) - y_rsf_test_minmax, c=\"orange\", label=\"Testing Data\")\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y_rsf_test_minmax.min(), xmax=y_rsf_test_minmax.max())\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the Model with MSE and R2\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MSE = mean_squared_error(y_rsf_test_minmax, predictions)\n",
    "r2 = model.score(X_test_minmax, y_rsf_test_minmax)\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RSF variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat model and fit to scaled training data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_minmax, y_var_train_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test_minmax)\n",
    "model.fit(X_train_minmax, y_var_train_minmax)\n",
    "\n",
    "plt.scatter(model.predict(X_train_minmax), model.predict(X_train_minmax) - y_var_train_minmax, c=\"blue\", label=\"Training Data\")\n",
    "plt.scatter(model.predict(X_test_minmax), model.predict(X_test_minmax) - y_var_test_minmax, c=\"orange\", label=\"Testing Data\")\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y_var_test_minmax.min(), xmax=y_var_test_minmax.max())\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the Model with MSE and R2\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MSE = mean_squared_error(y_var_test_minmax, predictions)\n",
    "r2 = model.score(X_test_minmax, y_var_test_minmax)\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Algorithms\n",
    "### Preprocessing - Transform RSF values to Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bear_rsf_mean\"].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [(df[\"bear_rsf_mean\"] < 6), (df[\"bear_rsf_mean\"] > 6) & (df[\"bear_rsf_mean\"] < 10), (df[\"bear_rsf_mean\"] > 10) & (df[\"bear_rsf_mean\"] < 15), (df[\"bear_rsf_mean\"]>15)]\n",
    "values = ['unknown','low', 'mid', 'high']\n",
    "df[\"bear_mean_cat\"] = np.select(conditions,values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bear_mean_cat\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change Threshold to 9\n",
    "df_cat_null = df [['land_avg_temp', 'land_max_temp', 'land_min_temp',\n",
    "       'land_ocean_avg_temp', 'north_min_temp_anomoly',\n",
    "       'north_max_temp_anomoly', 'north_mean_temp_anomoly', 'global_avg_co2',\n",
    "       'seaice_extent','bear_mean_cat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_null = df_cat_null.dropna(axis=0, how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_null.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign new variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_cat_null[['land_avg_temp', 'land_max_temp', 'land_min_temp',\n",
    "       'land_ocean_avg_temp', 'north_min_temp_anomoly',\n",
    "       'north_max_temp_anomoly', 'north_mean_temp_anomoly', 'global_avg_co2',\n",
    "       'seaice_extent']]\n",
    "y_cat = df_cat_null[\"bear_mean_cat\"]\n",
    "print(X.shape, y_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into testing and training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_cat_train, y_cat_test = train_test_split(X, y_cat, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMaxScalar to fit and transform X features and y target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit Transform using MinMaxScalar for X features\n",
    "X_input = []\n",
    "def rf_algo():\n",
    "    X_input = []\n",
    "    X_input_minmax = MinMaxScaler().fit(X_input)\n",
    "    y_taget = rf.predict(X_input_minmax)\n",
    "    rf\n",
    "    \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_minmax = MinMaxScaler().fit(X_train)\n",
    "\n",
    "X_train_minmax = X_minmax.transform(X_train)\n",
    "X_test_minmax = X_minmax.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creat model and fit to scaled training data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train_minmax, y_cat_train)\n",
    "print(f\"Training Data Score: {classifier.score(X_train, y_cat_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_cat_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Forest Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "y_cat_rf = df_cat_null[\"bear_mean_cat\"]\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf = rf.fit(X_train_minmax, y_cat_train)\n",
    "score = rf.score(X_test_minmax, y_cat_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "sorted(zip(rf.feature_importances_, X.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Random Forest Testing Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hypertune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 5)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 3)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encoding y_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_cat_train)\n",
    "encoded_y_train = label_encoder.transform(y_cat_train)\n",
    "encoded_y_test = label_encoder.transform(y_cat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)# Fit the random search model\n",
    "rf_random.fit(X_train_minmax, encoded_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2 = RandomForestClassifier(n_estimators=200, min_samples_split =5, min_samples_leaf = 4, max_features='auto', max_depth=60, bootstrap='True')\n",
    "rf2 = rf2.fit(X_train_minmax, encoded_y_train)\n",
    "score = rf2.score(X_test_minmax, encoded_y_test)\n",
    "\n",
    "print(f\"Random Forest Testing Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'rf_rsf.sav'\n",
    "joblib.dump(\"rsf_rsf\", filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Prediction: Den location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loc = df[['year_month', 'land_avg_temp', 'land_max_temp', 'land_min_temp',\n",
    "       'land_ocean_avg_temp', 'north_min_temp_anomoly',\n",
    "       'north_max_temp_anomoly', 'north_mean_temp_anomoly', 'global_avg_co2',\n",
    "       'seaice_extent', 'num_bears',\n",
    "       'avg_distance_traveled', 'avg_num_land_dens', 'avg_num_ice_dens',\n",
    "       'avg_num_active_dens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loc_null = df_loc.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_loc_null.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Climate X Bear Mobility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mob = df_loc_null[['year_month', 'land_avg_temp', 'land_max_temp', 'land_min_temp',\n",
    "       'land_ocean_avg_temp', 'north_min_temp_anomoly',\n",
    "       'north_max_temp_anomoly', 'north_mean_temp_anomoly', 'global_avg_co2',\n",
    "       'seaice_extent']]\n",
    "y_mob = df_loc_null[\"avg_distance_traveled\"].values.reshape(-1, 1)\n",
    "print(X_mob.shape, y_mob.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Land Dens Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_mob_train, X_mob_test, y_mob_train, y_mob_test = train_test_split(X_mob, y_mob, test_size=0.2, random_state=42)\n",
    "# X_train, X_test, y_var_train, y_var_test = train_test_split(X, y_var, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Fit Transform using MinMaxScalar for X features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_mob_minmax = MinMaxScaler().fit(X_mob_train)\n",
    "X_mob_train_minmax = X_mob_minmax.transform(X_mob_train)\n",
    "X_mob_test_minmax = X_mob_minmax.transform(X_mob_test)\n",
    "\n",
    "#Target value\n",
    "y_mob_minmax = MinMaxScaler().fit(y_mob_train)\n",
    "y_mob_land_train_minmax = y_mob_minmax.transform(y_mob_train)\n",
    "y_mob_land_test_minmax = y_mob_minmax.transform(y_mob_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression Analysis\n",
    "\n",
    "## Number of Land Dens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat model and fit to scaled training data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_den_train_minmax, y_den_land_train_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Prediction using a FIT model and plot\n",
    "predictions = model.predict(X_den_test_minmax)\n",
    "model.fit(X_den_train_minmax, y_den_land_train_minmax)\n",
    "\n",
    "plt.scatter(model.predict(X_den_train_minmax), model.predict(X_den_train_minmax) - y_den_land_train_minmax, c=\"blue\", label=\"Training Data\")\n",
    "plt.scatter(model.predict(X_den_test_minmax), model.predict(X_den_test_minmax) - y_den_land_test_minmax, c=\"orange\", label=\"Testing Data\")\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y_den_land_test_minmax.min(), xmax=y_den_land_test_minmax.max())\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the Model with MSE and R2\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MSE = mean_squared_error(y_den_land_test_minmax, predictions)\n",
    "r2 = model.score(X_den_test_minmax, y_den_land_test_minmax)\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range (1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_den_train_minmax, y_den_land_train)\n",
    "    train_score = knn.score(X_den_train_minmax, y_den_land_train)\n",
    "    test_score = knn.score(X_den_test_minmax, y_den_land_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "    \n",
    "plt.plot(range(1, 20, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 20, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 5: re-fit classifier with optimal k value\n",
    "knn = KNeighborsClassifier(n_neighbors = 13)\n",
    "knn.fit(X_den_train_minmax, y_den_land_train)\n",
    "print(\"k=15 Test Acc: %.3f\" %knn.score(X_den_test_minmax, y_den_land_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonAdv] *",
   "language": "python",
   "name": "conda-env-PythonAdv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
