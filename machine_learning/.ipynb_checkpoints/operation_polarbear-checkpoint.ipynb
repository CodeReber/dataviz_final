{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "!pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install joblib for saving\n",
    "# Restart kernel after installing \n",
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import missingno as msno\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://github.com/CodeReber/dataviz_final/blob/main/data/ml_compile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize missing values with MSNO\n",
    "msno.bar(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning: Climate x Resource Selection Factor (RSF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_rsf = df [['year_month', 'land_avg_temp', 'land_max_temp', 'land_min_temp',\n",
    "       'land_ocean_avg_temp', 'north_min_temp_anomoly',\n",
    "       'north_max_temp_anomoly', 'north_mean_temp_anomoly', 'global_avg_co2',\n",
    "       'seaice_extent', 'bear_rsf_mean', 'bear_rsf_var']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Drop null values\n",
    "df_rsf_null = df_rsf.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rsf_null.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "numerical = ['land_avg_temp', 'land_max_temp', 'land_min_temp',\n",
    "       'land_ocean_avg_temp', 'north_min_temp_anomoly',\n",
    "       'north_max_temp_anomoly', 'north_mean_temp_anomoly', 'global_avg_co2',\n",
    "       'seaice_extent']\n",
    "df_rsf_null[numerical].hist(bins=30, figsize=(15, 10), layout=(3, 3));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the Data\n",
    "\n",
    "## Assign X(features) and y(target) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_rsf_null[['land_avg_temp', 'land_max_temp', 'land_min_temp',\n",
    "       'land_ocean_avg_temp', 'north_min_temp_anomoly',\n",
    "       'north_max_temp_anomoly', 'north_mean_temp_anomoly', 'global_avg_co2',\n",
    "       'seaice_extent']]\n",
    "y_rsf = df_rsf_null[\"bear_rsf_mean\"].values.reshape(-1, 1)\n",
    "y_var = df_rsf_null[\"bear_rsf_var\"].values.reshape(-1, 1)\n",
    "print(X.shape, y_rsf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into testing and training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_rsf_train, y_rsf_test = train_test_split(X, y_rsf, test_size=0.2, random_state=42)\n",
    "# X_train, X_test, y_var_train, y_var_test = train_test_split(X, y_var, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinMaxScalar to fit and transform X features and y target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit Transform using MinMaxScalar for X features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_minmax = MinMaxScaler().fit(X_train)\n",
    "y_rsf_minmax = MinMaxScaler().fit(y_rsf_train)\n",
    "y_var_minmax = MinMaxScaler().fit(y_var_train)\n",
    "\n",
    "X_train_minmax = X_minmax.transform(X_train)\n",
    "X_test_minmax = X_minmax.transform(X_test)\n",
    "\n",
    "#Target value #1\n",
    "y_rsf_train_minmax = y_rsf_minmax.transform(y_rsf_train)\n",
    "y_rsf_test_minmax = y_rsf_minmax.transform(y_rsf_test)\n",
    "\n",
    "#Target value #2\n",
    "y_var_train_minmax = y_var_minmax.transform(y_var_train)\n",
    "y_var_test_minmax = y_var_minmax.transform(y_var_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Analysis\n",
    "\n",
    "## RSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat model and fit to scaled training data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_minmax, y_rsf_train_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Prediction using a FIT model and plot ==SEE BELOW FOR ALTERNATIVES==\n",
    "predictions = model.predict(X_test_minmax)\n",
    "model.fit(X_train_minmax, y_rsf_train_minmax)\n",
    "\n",
    "plt.scatter(model.predict(X_train_minmax), model.predict(X_train_minmax) - y_rsf_train_minmax, c=\"blue\", label=\"Training Data\")\n",
    "plt.scatter(model.predict(X_test_minmax), model.predict(X_test_minmax) - y_rsf_test_minmax, c=\"orange\", label=\"Testing Data\")\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y_rsf_test_minmax.min(), xmax=y_rsf_test_minmax.max())\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the Model with MSE and R2\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MSE = mean_squared_error(y_rsf_test_minmax, predictions)\n",
    "r2 = model.score(X_test_minmax, y_rsf_test_minmax)\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RSF variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat model and fit to scaled training data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_minmax, y_var_train_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test_minmax)\n",
    "model.fit(X_train_minmax, y_var_train_minmax)\n",
    "\n",
    "plt.scatter(model.predict(X_train_minmax), model.predict(X_train_minmax) - y_var_train_minmax, c=\"blue\", label=\"Training Data\")\n",
    "plt.scatter(model.predict(X_test_minmax), model.predict(X_test_minmax) - y_var_test_minmax, c=\"orange\", label=\"Testing Data\")\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y_var_test_minmax.min(), xmax=y_var_test_minmax.max())\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the Model with MSE and R2\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MSE = mean_squared_error(y_var_test_minmax, predictions)\n",
    "r2 = model.score(X_test_minmax, y_var_test_minmax)\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing - Transform RSF values to Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bear_rsf_mean\"].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [(df[\"bear_rsf_mean\"] < 6), (df[\"bear_rsf_mean\"] > 6) & (df[\"bear_rsf_mean\"] < 10), (df[\"bear_rsf_mean\"] > 10) & (df[\"bear_rsf_mean\"] < 15), (df[\"bear_rsf_mean\"]>15)]\n",
    "values = ['unknown','low', 'mid', 'high']\n",
    "df[\"bear_mean_cat\"] = np.select(conditions,values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bear_mean_cat\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change Threshold to 9\n",
    "df_cat_null = df [['land_avg_temp', 'land_max_temp', 'land_min_temp',\n",
    "       'land_ocean_avg_temp', 'north_min_temp_anomoly',\n",
    "       'north_max_temp_anomoly', 'north_mean_temp_anomoly', 'global_avg_co2',\n",
    "       'seaice_extent','bear_mean_cat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_null = df_cat_null.dropna(axis=0, how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_null.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign new variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_cat_null[['land_avg_temp', 'land_max_temp', 'land_min_temp',\n",
    "       'land_ocean_avg_temp', 'north_min_temp_anomoly',\n",
    "       'north_max_temp_anomoly', 'north_mean_temp_anomoly', 'global_avg_co2',\n",
    "       'seaice_extent']]\n",
    "y_cat = df_cat_null[\"bear_mean_cat\"]\n",
    "print(X.shape, y_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into testing and training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_cat_train, y_cat_test = train_test_split(X, y_cat, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinMaxScalar to fit and transform X features and y target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit Transform using MinMaxScalar for X features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_minmax = MinMaxScaler().fit(X_train)\n",
    "\n",
    "X_train_minmax = X_minmax.transform(X_train)\n",
    "X_test_minmax = X_minmax.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Analysis\n",
    "\n",
    "## RSF Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creat model and fit to scaled training data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train_minmax, y_cat_train)\n",
    "print(f\"Training Data Score: {classifier.score(X_train, y_cat_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_cat_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Analysis\n",
    "\n",
    "## RSF Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "y_cat_rf = df_cat_null[\"bear_mean_cat\"]\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf = rf.fit(X_train_minmax, y_cat_train)\n",
    "score = rf.score(X_test_minmax, y_cat_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "sorted(zip(rf.feature_importances_, X.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Random Forest Testing Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hypertune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 5)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 3)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encoding y_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_cat_train)\n",
    "encoded_y_train = label_encoder.transform(y_cat_train)\n",
    "encoded_y_test = label_encoder.transform(y_cat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)# Fit the random search model\n",
    "rf_random.fit(X_train_minmax, encoded_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2 = RandomForestClassifier(n_estimators=200, min_samples_split =5, min_samples_leaf = 4, max_features='auto', max_depth=60, bootstrap='True')\n",
    "rf2 = rf2.fit(X_train_minmax, encoded_y_train)\n",
    "score = rf2.score(X_test_minmax, encoded_y_test)\n",
    "\n",
    "print(f\"Random Forest Testing Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Prediction: Den location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dens = df[['year_month', 'land_avg_temp', 'land_max_temp', 'land_min_temp',\n",
    "       'land_ocean_avg_temp', 'north_min_temp_anomoly',\n",
    "       'north_max_temp_anomoly', 'north_mean_temp_anomoly', 'global_avg_co2',\n",
    "       'seaice_extent','num_land_dens',\n",
    "       'num_ice_dens', 'num_active_dens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dens.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dens_null = df_dens.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dens_null.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_den = df_dens_null[['land_avg_temp', 'land_max_temp', 'land_min_temp',\n",
    "       'land_ocean_avg_temp', 'north_min_temp_anomoly',\n",
    "       'north_max_temp_anomoly', 'north_mean_temp_anomoly', 'global_avg_co2',\n",
    "       'seaice_extent', \"num_active_dens\"]]\n",
    "y_den_land = df_dens_null[\"num_land_dens\"].values.reshape(-1, 1)\n",
    "y_den_ice = df_dens_null[\"num_ice_dens\"].values.reshape(-1,1)\n",
    "print(X_den.shape, y_den_land.shape, y_den_ice.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Land Dens Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_den_train, X_den_test, y_den_land_train, y_den_land_test = train_test_split(X_den, y_den_land, test_size=0.2, random_state=42)\n",
    "# X_train, X_test, y_var_train, y_var_test = train_test_split(X, y_var, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Fit Transform using MinMaxScalar for X features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_den_minmax = MinMaxScaler().fit(X_den_train)\n",
    "X_den_train_minmax = X_den_minmax.transform(X_den_train)\n",
    "X_den_test_minmax = X_den_minmax.transform(X_den_test)\n",
    "\n",
    "#Target value #1\n",
    "y_den_minmax = MinMaxScaler().fit(y_den_land_train)\n",
    "y_den_land_train_minmax = y_den_minmax.transform(y_den_land_train)\n",
    "y_den_land_test_minmax = y_den_minmax.transform(y_den_land_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression Analysis\n",
    "\n",
    "## Number of Land Dens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat model and fit to scaled training data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_den_train_minmax, y_den_land_train_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Prediction using a FIT model and plot\n",
    "predictions = model.predict(X_den_test_minmax)\n",
    "model.fit(X_den_train_minmax, y_den_land_train_minmax)\n",
    "\n",
    "plt.scatter(model.predict(X_den_train_minmax), model.predict(X_den_train_minmax) - y_den_land_train_minmax, c=\"blue\", label=\"Training Data\")\n",
    "plt.scatter(model.predict(X_den_test_minmax), model.predict(X_den_test_minmax) - y_den_land_test_minmax, c=\"orange\", label=\"Testing Data\")\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y_den_land_test_minmax.min(), xmax=y_den_land_test_minmax.max())\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the Model with MSE and R2\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MSE = mean_squared_error(y_den_land_test_minmax, predictions)\n",
    "r2 = model.score(X_den_test_minmax, y_den_land_test_minmax)\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range (1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_den_train_minmax, y_den_land_train)\n",
    "    train_score = knn.score(X_den_train_minmax, y_den_land_train)\n",
    "    test_score = knn.score(X_den_test_minmax, y_den_land_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "    \n",
    "plt.plot(range(1, 20, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 20, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 5: re-fit classifier with optimal k value\n",
    "knn = KNeighborsClassifier(n_neighbors = 13)\n",
    "knn.fit(X_den_train_minmax, y_den_land_train)\n",
    "print(\"k=15 Test Acc: %.3f\" %knn.score(X_den_test_minmax, y_den_land_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonAdv] *",
   "language": "python",
   "name": "conda-env-PythonAdv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
