{
 "cells": [
  {
   "source": [
    "# Predicting Impact of Climate on Polar Bear Habitat Selection\n",
    "\n",
    "## Dataset from 1985 - 2016 \n",
    "\n",
    "#### Machine Learning Pipeline Overview\n",
    "1. Import and clean the dataset -- remove null values, select relevant columns, remove outliers\n",
    "2. Convert RSF values to categorical values\n",
    "3. Assign features and target values then split data into training and testing datasets\n",
    "4. Normalize quantitative data using MinMaxScalar\n",
    "4. Define, Train and Score Models\n",
    "5. Select highest scoring model and hypertune (Random Forest)\n",
    "6. Save model using pickle for future predictions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already up-to-date: sklearn in /opt/anaconda3/lib/python3.7/site-packages (0.0)\nRequirement already satisfied, skipping upgrade: scikit-learn in /opt/anaconda3/lib/python3.7/site-packages (from sklearn) (0.22.1)\nRequirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/anaconda3/lib/python3.7/site-packages (from scikit-learn->sklearn) (0.14.1)\nRequirement already satisfied, skipping upgrade: scipy>=0.17.0 in /opt/anaconda3/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.4.1)\nRequirement already satisfied, skipping upgrade: numpy>=1.11.0 in /opt/anaconda3/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.18.1)\n"
     ]
    }
   ],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "!pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.7/site-packages (0.14.1)\n"
     ]
    }
   ],
   "source": [
    "# install joblib for saving\n",
    "# Restart kernel after installing \n",
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "# import missingno as msno\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../../data/ml_compile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       land_avg_temp  land_max_temp  land_min_temp  land_ocean_avg_temp  \\\n",
       "count    1392.000000    1392.000000    1392.000000          1392.000000   \n",
       "mean        8.762454      14.516995       3.000047            15.317030   \n",
       "std         4.199958       4.294911       4.114758             1.259405   \n",
       "min         1.395000       7.082000      -4.298000            12.839000   \n",
       "25%         4.655750      10.426250      -1.103250            14.150750   \n",
       "50%         9.087500      14.899000       3.213500            15.373000   \n",
       "75%        12.953000      18.867000       7.048000            16.477750   \n",
       "max        15.482000      21.320000       9.715000            17.611000   \n",
       "\n",
       "       north_min_temp_anomoly  north_max_temp_anomoly  \\\n",
       "count             1428.000000             1434.000000   \n",
       "mean                 0.122602                0.213536   \n",
       "std                  0.709268                0.620087   \n",
       "min                 -1.951000               -1.772000   \n",
       "25%                 -0.354250               -0.184750   \n",
       "50%                  0.022500                0.140500   \n",
       "75%                  0.583250                0.563500   \n",
       "max                  2.970000                2.805000   \n",
       "\n",
       "       north_mean_temp_anomoly  global_avg_co2  seaice_extent  bear_rsf_mean  \\\n",
       "count              1446.000000      752.000000     506.000000     334.000000   \n",
       "mean                  0.213620      355.582926      11.405146      15.820979   \n",
       "std                   0.630979       28.949294       3.252910       2.430975   \n",
       "min                  -1.647000      312.430000       3.565600       6.093212   \n",
       "25%                  -0.198000      329.112500       8.571152      14.872230   \n",
       "50%                   0.098000      352.880000      12.095933      16.388356   \n",
       "75%                   0.576500      378.857500      14.318582      17.471275   \n",
       "max                   2.877000      417.070000      16.341938      20.000000   \n",
       "\n",
       "       ...  latitude_rsf    loc_zone  num_bears  avg_distance_traveled  \\\n",
       "count  ...    334.000000  334.000000  84.000000           8.400000e+01   \n",
       "mean   ...     71.788726    3.886228   6.690476           5.916332e+08   \n",
       "std    ...      1.610578    2.351714   3.951441           6.769937e+08   \n",
       "min    ...     67.796405    0.000000   1.000000           1.784230e+05   \n",
       "25%    ...     70.898015    2.000000   3.000000           1.296206e+08   \n",
       "50%    ...     71.314351    4.000000   7.000000           2.588397e+08   \n",
       "75%    ...     72.192211    5.000000   8.000000           9.286488e+08   \n",
       "max    ...     78.895838    9.000000  17.000000           2.617030e+09   \n",
       "\n",
       "       avg_num_land_dens  avg_num_ice_dens  avg_num_active_dens     den_lat  \\\n",
       "count          84.000000         84.000000            84.000000   84.000000   \n",
       "mean           41.553384        504.157876            40.258267 -147.752653   \n",
       "std            76.629269        481.543071            70.866545    9.706844   \n",
       "min             0.000000          0.000000             0.000000 -165.942373   \n",
       "25%             0.000000        171.946429             0.000000 -154.116038   \n",
       "50%            10.083333        270.750000             0.000000 -149.928811   \n",
       "75%            55.937500        820.386905            68.392857 -143.258156   \n",
       "max           422.333333       2012.500000           333.000000 -120.994143   \n",
       "\n",
       "        den_long    den_loc  \n",
       "count  84.000000  84.000000  \n",
       "mean   72.663690   4.404762  \n",
       "std     1.605944   2.657651  \n",
       "min    70.318495   0.000000  \n",
       "25%    71.463159   2.000000  \n",
       "50%    72.200680   5.000000  \n",
       "75%    73.719433   7.000000  \n",
       "max    76.812461   9.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>land_avg_temp</th>\n      <th>land_max_temp</th>\n      <th>land_min_temp</th>\n      <th>land_ocean_avg_temp</th>\n      <th>north_min_temp_anomoly</th>\n      <th>north_max_temp_anomoly</th>\n      <th>north_mean_temp_anomoly</th>\n      <th>global_avg_co2</th>\n      <th>seaice_extent</th>\n      <th>bear_rsf_mean</th>\n      <th>...</th>\n      <th>latitude_rsf</th>\n      <th>loc_zone</th>\n      <th>num_bears</th>\n      <th>avg_distance_traveled</th>\n      <th>avg_num_land_dens</th>\n      <th>avg_num_ice_dens</th>\n      <th>avg_num_active_dens</th>\n      <th>den_lat</th>\n      <th>den_long</th>\n      <th>den_loc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1392.000000</td>\n      <td>1392.000000</td>\n      <td>1392.000000</td>\n      <td>1392.000000</td>\n      <td>1428.000000</td>\n      <td>1434.000000</td>\n      <td>1446.000000</td>\n      <td>752.000000</td>\n      <td>506.000000</td>\n      <td>334.000000</td>\n      <td>...</td>\n      <td>334.000000</td>\n      <td>334.000000</td>\n      <td>84.000000</td>\n      <td>8.400000e+01</td>\n      <td>84.000000</td>\n      <td>84.000000</td>\n      <td>84.000000</td>\n      <td>84.000000</td>\n      <td>84.000000</td>\n      <td>84.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>8.762454</td>\n      <td>14.516995</td>\n      <td>3.000047</td>\n      <td>15.317030</td>\n      <td>0.122602</td>\n      <td>0.213536</td>\n      <td>0.213620</td>\n      <td>355.582926</td>\n      <td>11.405146</td>\n      <td>15.820979</td>\n      <td>...</td>\n      <td>71.788726</td>\n      <td>3.886228</td>\n      <td>6.690476</td>\n      <td>5.916332e+08</td>\n      <td>41.553384</td>\n      <td>504.157876</td>\n      <td>40.258267</td>\n      <td>-147.752653</td>\n      <td>72.663690</td>\n      <td>4.404762</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>4.199958</td>\n      <td>4.294911</td>\n      <td>4.114758</td>\n      <td>1.259405</td>\n      <td>0.709268</td>\n      <td>0.620087</td>\n      <td>0.630979</td>\n      <td>28.949294</td>\n      <td>3.252910</td>\n      <td>2.430975</td>\n      <td>...</td>\n      <td>1.610578</td>\n      <td>2.351714</td>\n      <td>3.951441</td>\n      <td>6.769937e+08</td>\n      <td>76.629269</td>\n      <td>481.543071</td>\n      <td>70.866545</td>\n      <td>9.706844</td>\n      <td>1.605944</td>\n      <td>2.657651</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.395000</td>\n      <td>7.082000</td>\n      <td>-4.298000</td>\n      <td>12.839000</td>\n      <td>-1.951000</td>\n      <td>-1.772000</td>\n      <td>-1.647000</td>\n      <td>312.430000</td>\n      <td>3.565600</td>\n      <td>6.093212</td>\n      <td>...</td>\n      <td>67.796405</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.784230e+05</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-165.942373</td>\n      <td>70.318495</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>4.655750</td>\n      <td>10.426250</td>\n      <td>-1.103250</td>\n      <td>14.150750</td>\n      <td>-0.354250</td>\n      <td>-0.184750</td>\n      <td>-0.198000</td>\n      <td>329.112500</td>\n      <td>8.571152</td>\n      <td>14.872230</td>\n      <td>...</td>\n      <td>70.898015</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>1.296206e+08</td>\n      <td>0.000000</td>\n      <td>171.946429</td>\n      <td>0.000000</td>\n      <td>-154.116038</td>\n      <td>71.463159</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>9.087500</td>\n      <td>14.899000</td>\n      <td>3.213500</td>\n      <td>15.373000</td>\n      <td>0.022500</td>\n      <td>0.140500</td>\n      <td>0.098000</td>\n      <td>352.880000</td>\n      <td>12.095933</td>\n      <td>16.388356</td>\n      <td>...</td>\n      <td>71.314351</td>\n      <td>4.000000</td>\n      <td>7.000000</td>\n      <td>2.588397e+08</td>\n      <td>10.083333</td>\n      <td>270.750000</td>\n      <td>0.000000</td>\n      <td>-149.928811</td>\n      <td>72.200680</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>12.953000</td>\n      <td>18.867000</td>\n      <td>7.048000</td>\n      <td>16.477750</td>\n      <td>0.583250</td>\n      <td>0.563500</td>\n      <td>0.576500</td>\n      <td>378.857500</td>\n      <td>14.318582</td>\n      <td>17.471275</td>\n      <td>...</td>\n      <td>72.192211</td>\n      <td>5.000000</td>\n      <td>8.000000</td>\n      <td>9.286488e+08</td>\n      <td>55.937500</td>\n      <td>820.386905</td>\n      <td>68.392857</td>\n      <td>-143.258156</td>\n      <td>73.719433</td>\n      <td>7.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>15.482000</td>\n      <td>21.320000</td>\n      <td>9.715000</td>\n      <td>17.611000</td>\n      <td>2.970000</td>\n      <td>2.805000</td>\n      <td>2.877000</td>\n      <td>417.070000</td>\n      <td>16.341938</td>\n      <td>20.000000</td>\n      <td>...</td>\n      <td>78.895838</td>\n      <td>9.000000</td>\n      <td>17.000000</td>\n      <td>2.617030e+09</td>\n      <td>422.333333</td>\n      <td>2012.500000</td>\n      <td>333.000000</td>\n      <td>-120.994143</td>\n      <td>76.812461</td>\n      <td>9.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows Ã— 22 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = df[['land_avg_temp', 'land_max_temp', 'land_min_temp',\n",
    "#        'land_ocean_avg_temp', 'north_min_temp_anomoly',\n",
    "#        'north_max_temp_anomoly', 'north_mean_temp_anomoly', 'global_avg_co2',\n",
    "#        'seaice_extent', 'bear_rsf_mean']]\n",
    "df = df[['land_avg_temp', 'land_ocean_avg_temp','global_avg_co2',\n",
    "       'seaice_extent', 'bear_rsf_mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       land_avg_temp  land_ocean_avg_temp  global_avg_co2  seaice_extent  \\\n",
       "count     331.000000           331.000000      331.000000     331.000000   \n",
       "mean        9.385082            15.712589      372.225619      11.357481   \n",
       "std         4.121994             1.225211       16.649756       3.220250   \n",
       "min         2.710000            13.566000      343.130000       3.565600   \n",
       "25%         5.552000            14.511000      356.145000       8.513177   \n",
       "50%         9.618000            15.811000      372.250000      12.016400   \n",
       "75%        13.443000            16.884000      386.235000      14.326682   \n",
       "max        15.482000            17.611000      403.960000      16.050143   \n",
       "\n",
       "       bear_rsf_mean  \n",
       "count     331.000000  \n",
       "mean       15.851405  \n",
       "std         2.392539  \n",
       "min         6.093212  \n",
       "25%        14.928223  \n",
       "50%        16.396830  \n",
       "75%        17.470912  \n",
       "max        20.000000  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>land_avg_temp</th>\n      <th>land_ocean_avg_temp</th>\n      <th>global_avg_co2</th>\n      <th>seaice_extent</th>\n      <th>bear_rsf_mean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>331.000000</td>\n      <td>331.000000</td>\n      <td>331.000000</td>\n      <td>331.000000</td>\n      <td>331.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>9.385082</td>\n      <td>15.712589</td>\n      <td>372.225619</td>\n      <td>11.357481</td>\n      <td>15.851405</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>4.121994</td>\n      <td>1.225211</td>\n      <td>16.649756</td>\n      <td>3.220250</td>\n      <td>2.392539</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>2.710000</td>\n      <td>13.566000</td>\n      <td>343.130000</td>\n      <td>3.565600</td>\n      <td>6.093212</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>5.552000</td>\n      <td>14.511000</td>\n      <td>356.145000</td>\n      <td>8.513177</td>\n      <td>14.928223</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>9.618000</td>\n      <td>15.811000</td>\n      <td>372.250000</td>\n      <td>12.016400</td>\n      <td>16.396830</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>13.443000</td>\n      <td>16.884000</td>\n      <td>386.235000</td>\n      <td>14.326682</td>\n      <td>17.470912</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>15.482000</td>\n      <td>17.611000</td>\n      <td>403.960000</td>\n      <td>16.050143</td>\n      <td>20.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df = df.dropna(axis=0, how=\"any\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "16.39683045\n"
     ]
    }
   ],
   "source": [
    "from statistics import median \n",
    "print(median(df[\"bear_rsf_mean\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Algorithms\n",
    "### Preprocessing - Transform RSF values to Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [(df[\"bear_rsf_mean\"] < 15), (df[\"bear_rsf_mean\"] > 15) & (df[\"bear_rsf_mean\"] < 18), (df[\"bear_rsf_mean\"]>18)]\n",
    "values = ['low', 'mid', 'high']\n",
    "df[\"bear_mean_cat\"] = np.select(conditions,values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change Threshold to 9\n",
    "df_cat = df [['land_avg_temp', 'land_ocean_avg_temp', 'global_avg_co2',\n",
    "       'seaice_extent','bear_mean_cat']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign new variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(331, 4) (331,)\n"
     ]
    }
   ],
   "source": [
    "X = df_cat[['land_avg_temp', 'land_ocean_avg_temp', 'global_avg_co2',\n",
    "       'seaice_extent']]\n",
    "y_cat = df_cat[\"bear_mean_cat\"]\n",
    "print(X.shape, y_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into testing and training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_cat_train, y_cat_test = train_test_split(X, y_cat, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMaxScalar to fit and transform X features and y target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit Transform using MinMaxScalar for X features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_minmax = MinMaxScaler().fit(X_train)\n",
    "\n",
    "X_train_minmax = X_minmax.transform(X_train)\n",
    "X_test_minmax = X_minmax.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "y_cat_rf = df_cat[\"bear_mean_cat\"]\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf = rf.fit(X_train_minmax, y_cat_train)\n",
    "score = rf.score(X_test_minmax, y_cat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_cat_train)\n",
    "encoded_y_train = label_encoder.transform(y_cat_train)\n",
    "encoded_y_test = label_encoder.transform(y_cat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'high': 0, 'low': 1, 'mid': 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_cat_train)\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6268656716417911"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "rf2 = RandomForestClassifier(n_estimators=200, min_samples_split =5, min_samples_leaf = 4, max_features='auto', max_depth=60, bootstrap='True')\n",
    "rf2 = rf2.fit(X_train_minmax, encoded_y_train)\n",
    "score = rf2.score(X_test_minmax, encoded_y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pickle import dump\n",
    "pickle.dump(rf2, open(\"../../models/rf_rsf2.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_file = open(\"rf_rsf.pkl\", \"rb\")\n",
    "with open(\"../../models/rf_rsf2.pkl\", \"rb\") as f:\n",
    "    model_object = pickle.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap='True', ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=60, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=4, min_samples_split=5,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "model_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}