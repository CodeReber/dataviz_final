{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering to Identify Zones based on Polar Bear Location for Downstream Machine Learning on Den Location\n",
    "\n",
    "### The dataset \"data/polarbears/pB_2009_2016.csv\" contains robust latitude and longitudinal data of polar bears every 30 minutes from 2009 - 2016.\n",
    "\n",
    "#### Machine Learning Pipeline Overview\n",
    "1. Import and clean the dataset -- remove null values, select relevant columns, remove outliers\n",
    "2. Plot coordinates onto a map for visualizing \"zones\" or k clusters\n",
    "3. Select k based on a high score with useful resolution for locating polar bears across a massive surface area.\n",
    "4. Create, train and fit the model based on k clusters using the 2009-2016 dataset\n",
    "5. Apply our model to the 1985-2016 polar bear dataset for final machine learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns; sns.set()\n",
    "import csv\n",
    "import plotly.express as px\n",
    "import time \n",
    "import matplotlib.cm as cm\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoSeries\n",
    "from shapely.geometry import Point\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Clean the Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import Dataset\n",
    "df = pd.read_csv('../../../data/polarbears/pB_2009_2016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 342315 entries, 0 to 342314\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   bear_id       342315 non-null  object \n",
      " 1   GMTdate       342315 non-null  object \n",
      " 2   GMTtime       342315 non-null  object \n",
      " 3   long          342315 non-null  float64\n",
      " 4   lat           342315 non-null  float64\n",
      " 5   raw_act       342315 non-null  float64\n",
      " 6   standard_act  342315 non-null  float64\n",
      " 7   active_den    342315 non-null  int64  \n",
      " 8   habitat       342315 non-null  object \n",
      " 9   Unnamed: 9    0 non-null       float64\n",
      " 10  Unnamed: 10   0 non-null       float64\n",
      " 11  Unnamed: 11   3034 non-null    object \n",
      "dtypes: float64(6), int64(1), object(5)\n",
      "memory usage: 31.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove unnamed columns\n",
    "df = df[['bear_id', 'GMTdate', 'GMTtime', 'long', 'lat', 'raw_act',\n",
    "       'standard_act', 'active_den', 'habitat']]\n",
    "#Convert GMTdate to datetime format\n",
    "df[\"GMTdate\"]=pd.to_datetime(den_df[\"GMTdate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 342315 entries, 0 to 342314\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count   Dtype         \n",
      "---  ------        --------------   -----         \n",
      " 0   bear_id       342315 non-null  object        \n",
      " 1   GMTdate       342315 non-null  datetime64[ns]\n",
      " 2   GMTtime       342315 non-null  object        \n",
      " 3   long          342315 non-null  float64       \n",
      " 4   lat           342315 non-null  float64       \n",
      " 5   raw_act       342315 non-null  float64       \n",
      " 6   standard_act  342315 non-null  float64       \n",
      " 7   active_den    342315 non-null  int64         \n",
      " 8   habitat       342315 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(4), int64(1), object(3)\n",
      "memory usage: 23.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a DataFrame with latitude and longitude ONLY\n",
    "df_bear = df[['long', 'lat']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140 extreme outliers removed\n",
      "Shape of filtered df_pickup: (342175, 2)\n"
     ]
    }
   ],
   "source": [
    "# Drop lat/longs of extreme outliers below 0.01 percentile or above 99.99 percentile\n",
    "df_bear_filtered = df_bear[(df_bear.quantile(0.0001) < df_bear) & (df_bear < df_bear.quantile(0.9999))]\n",
    "df_bear_filtered = df_bear_filtered.dropna(how='any')\n",
    "\n",
    "print(f'{df_bear.shape[0] - df_bear_filtered.shape[0]} extreme outliers removed')\n",
    "print(f'Shape of filtered df_pickup: {df_bear_filtered.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize ClPlot coordinates and clusters onto Map of Arctic Circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_geolocation_by_cluster(df,cluster,title,centers,filename):\n",
    "    \n",
    "    \n",
    "    # Transform df into geodataframe\n",
    "    geo_df = gpd.GeoDataFrame(df.drop(['long', 'lat'], axis=1),\n",
    "                           crs={'init': 'epsg:4326'},\n",
    "                           geometry=[Point(xy) for xy in zip(df.long, df.lat)])\n",
    "      \n",
    "    # Set figure size\n",
    "    fig, ax = plt.subplots(figsize=(10,5))\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "    # Import ArcticShape Files\n",
    "    world_full = gpd.read_file(\"../../../data/shapefiles/arctic_full.shp\")\n",
    "    world_full.plot(ax=ax, alpha=0.4, edgecolor='darkgrey', color='lightgrey', zorder=1)\n",
    "    \n",
    "    # Plot coordinates from geo_df on top of NYC map\n",
    "    if cluster is not None:\n",
    "        geo_df.plot(ax=ax, column=cluster, alpha=0.5, \n",
    "                    cmap='viridis', linewidth=0.8, zorder=2)\n",
    "        if centers is not None:\n",
    "            centers_gseries = GeoSeries(map(Point, zip(centers[:,0], centers[:,1])))\n",
    "            centers_gseries.plot(ax=ax, alpha=0.8, color='black', markersize=100, zorder=3)\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.xlabel('longitude')\n",
    "        plt.ylabel('latitude')\n",
    "        plt.ylim(50, 90)\n",
    "        plt.xlim(-180, -100)\n",
    "        plt.show()\n",
    "        \n",
    "        if filename is not None:\n",
    "            fig.savefig(f'{filename}', bbox_inches='tight', dpi=300)\n",
    "    else:\n",
    "        geo_df.plot(ax=ax, alpha=0.5, cmap='viridis', linewidth=0.8, legend=True, zorder=2)\n",
    "        plt.title(title)\n",
    "        plt.xlabel('longitude')\n",
    "        plt.ylabel('latitude')\n",
    "        plt.ylim(50, 90)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    fig.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ssd = []\n",
    "\n",
    "for i in range(2, 16):\n",
    "    # Find clusters\n",
    "    km = MiniBatchKMeans(n_clusters=i)\n",
    "    km.fit_predict(df_bear_filtered)\n",
    "    \n",
    "    # Label cluster centers\n",
    "    centers = km.cluster_centers_\n",
    "    \n",
    "    # Calculate sum of squared distances\n",
    "    ssd.append(km.inertia_)\n",
    "    \n",
    "    # Get cluster center\n",
    "    df_bear_filtered['cluster'] = km.labels_\n",
    "    \n",
    "    # Plot lat/long and clusters on map\n",
    "    plot_geolocation_by_cluster(df_bear_filtered, cluster='cluster', title= f'K-Means: Polar Bear Locations grouped into {i} clusters', centers=centers, filename=f'../../../machine_learning/plots/bear_kmeans_{i}_clusters.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def png_to_gif(path_to_images, save_file_path, duration=500):\n",
    "    frames = []\n",
    "    images = glob.glob(f'{path_to_images}')\n",
    "    \n",
    "    for i in sorted(images): \n",
    "        im = Image.open(i)\n",
    "        im = im.resize((550,389),Image.ANTIALIAS)\n",
    "        frames.append(im.copy())\n",
    "    \n",
    "    frames[0].save(f'{save_file_path}', format='GIF', append_images=frames[1:], save_all=True,\n",
    "                   duration=duration, loop=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "png_to_gif(path_to_images='../../../machine_learning/plots/*.png', \n",
    "           save_file_path='../../../machine_learning/plots/bear_kmeans_clusters.gif',\n",
    "           duration=500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<img src=\"../../../machine_learning/plots/bear_kmeans_clusters.gif\">')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run standard Elbow Cuver for KMeans\n",
    "K_clusters = range(1,16)\n",
    "kmeans = [KMeans(n_clusters=i) for i in K_clusters]\n",
    "\n",
    "Y_axis = df_bear_filtered[['lat']]\n",
    "X_axis = df_bear_filtered[['long']]\n",
    "score = [kmeans[i].fit(Y_axis).score(Y_axis) for i in range(len(kmeans))]\n",
    "\n",
    "# Visualize\n",
    "plt.plot(K_clusters, score)\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Elbow Curve')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create KMeans Model for Den Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 9, 9, ..., 1, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km = MiniBatchKMeans(n_clusters=10)\n",
    "km.fit_predict(df_bear_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save lat/lon labeling model\n",
    "import pickle\n",
    "pickle.dump(km, open(\"../../models/den_loc_km.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../models/den_loc_km.pkl\", \"rb\") as f:\n",
    "    model_object = pickle.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform dataframe to match compiled file (2009 - 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "den_df = den_df.groupby(pd.Grouper(key=\"GMTdate\", freq='M')).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "den_df = den_df[[\"long\", \"lat\"]].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Dataset to Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long</th>\n",
       "      <th>lat</th>\n",
       "      <th>loc_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-147.079956</td>\n",
       "      <td>70.518492</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-148.079600</td>\n",
       "      <td>70.881717</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-153.360651</td>\n",
       "      <td>71.689841</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-158.677270</td>\n",
       "      <td>72.884016</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-153.710525</td>\n",
       "      <td>73.217770</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         long        lat  loc_zone\n",
       "0 -147.079956  70.518492         3\n",
       "1 -148.079600  70.881717         3\n",
       "2 -153.360651  71.689841         8\n",
       "3 -158.677270  72.884016         9\n",
       "4 -153.710525  73.217770         8"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.fit_predict(den_df)\n",
    "den_df[\"loc_zone\"] = km.labels_\n",
    "den_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1985-2016 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('../../../data/polarbears/pB_1985_2016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 263886 entries, 0 to 263885\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   BearID_rsf       263886 non-null  int64  \n",
      " 1   DateTimeUTC_rsf  263886 non-null  object \n",
      " 2   latitude_rsf     263886 non-null  float64\n",
      " 3   longitude_rsf    263886 non-null  float64\n",
      " 4   season           263886 non-null  object \n",
      " 5   period           263886 non-null  int64  \n",
      " 6   lc94_rsf         263886 non-null  object \n",
      " 7   eaInterval_rsf   263886 non-null  int64  \n",
      "dtypes: float64(2), int64(3), object(3)\n",
      "memory usage: 16.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"DateTimeUTC_rsf\"]=pd.to_datetime(df2[\"DateTimeUTC_rsf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.groupby(pd.Grouper(key=\"DateTimeUTC_rsf\", freq='M')).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 334 entries, 0 to 373\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   longitude_rsf  334 non-null    float64\n",
      " 1   latitude_rsf   334 non-null    float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 7.8 KB\n"
     ]
    }
   ],
   "source": [
    "df2 = df2[[\"longitude_rsf\", \"latitude_rsf\"]]\n",
    "df2 = df2.dropna()\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude_rsf</th>\n",
       "      <th>latitude_rsf</th>\n",
       "      <th>loc_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-145.622023</td>\n",
       "      <td>70.686773</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-141.682085</td>\n",
       "      <td>70.557746</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-146.170957</td>\n",
       "      <td>71.341745</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-152.879137</td>\n",
       "      <td>71.677074</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-154.493710</td>\n",
       "      <td>72.594194</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude_rsf  latitude_rsf  loc_zone\n",
       "0    -145.622023     70.686773         4\n",
       "1    -141.682085     70.557746         3\n",
       "2    -146.170957     71.341745         4\n",
       "3    -152.879137     71.677074         7\n",
       "4    -154.493710     72.594194         5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.fit_predict(df2)\n",
    "df2[\"loc_zone\"] = km.labels_\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv (r'../../../data/polarbears/latlonzone_1985_2016.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "den_df.to_csv (r'../../../data/polarbears/latlonzone_2009_2016.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
